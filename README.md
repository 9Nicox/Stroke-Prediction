# ğŸ§  Stroke Prediction â€“ Donâ€™t Be Fooled by Big Numbers

## ğŸ“Œ Description
This project explores the prediction of stroke risk using the [Kaggle Stroke Prediction dataset](https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset).  
The main goal is to highlight the challenges of **imbalanced datasets** and to show why metrics like **accuracy can be misleading** in a medical context.

## ğŸ“Š Dataset
- **Source**: Kaggle â€“ Stroke Prediction Dataset  
- **Target variable**: `stroke` (binary classification)  
- **Class imbalance**:  
  - Non-stroke: ~95%  
  - Stroke: ~5%  

âš ï¸ This imbalance makes prediction difficult and explains why high accuracy is not always meaningful.

## âš™ï¸ Methods
- **Exploratory Data Analysis (EDA)**  
- **Decision Tree Classifier** â†’ first model with very high accuracy but poor recall  
- **Handling imbalance**: stratified split, class weighting  
- **Hyperparameter tuning**  
- **Evaluation metrics**: Accuracy, Recall, F1-score, ROC-AUC, Confusion Matrix  

## ğŸ§¾ Key Takeaways
- A model can achieve **95% accuracy** simply by predicting "non-stroke" for everyone.  
- **Recall and ROC-AUC** are more appropriate metrics for evaluating medical prediction models.  
- Feature importance analysis highlights age, hypertension, and heart disease as strong predictors.  
- Proper handling of imbalance (e.g., class weights) significantly improves the modelâ€™s usefulness.

## ğŸ“‚ Repository Structure
Stroke-Prediction/

â”œâ”€â”€ notebooks/

â”‚ â””â”€â”€ stroke-prediction.ipynb

â”œâ”€â”€ figures/ # (plots and visualizations - to be added later)

â””â”€â”€ README.md


## ğŸš€ Next Steps
- Add SHAP analysis for interpretability  
- Try oversampling/undersampling techniques (SMOTE, random under/oversampling)  
- Compare with more models (e.g., Logistic Regression, Random Forest, XGBoost)  

---

âœï¸ Author: Nicolas (9Nicox)  
ğŸ“… Initial work: 2023 â€“ Updated 2025  
