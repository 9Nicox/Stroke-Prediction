{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4029610,"sourceType":"datasetVersion","datasetId":2387714}],"dockerImageVersionId":30527,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 2 - Data preparation","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2025-09-19T13:27:25.529486Z","iopub.execute_input":"2025-09-19T13:27:25.52985Z","iopub.status.idle":"2025-09-19T13:27:25.545863Z","shell.execute_reply.started":"2025-09-19T13:27:25.52982Z","shell.execute_reply":"2025-09-19T13:27:25.544624Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We are going to transform certain data into numerical categories","metadata":{}},{"cell_type":"code","source":"df['ever_married'] = [ 0 if i !='Yes' else 1 for i in df['ever_married'] ]\ndf['gender'] = [0 if i != 'Female' else 1 for i in df['gender']]","metadata":{"execution":{"iopub.status.busy":"2025-09-19T13:27:25.547588Z","iopub.execute_input":"2025-09-19T13:27:25.548703Z","iopub.status.idle":"2025-09-19T13:27:25.560469Z","shell.execute_reply.started":"2025-09-19T13:27:25.548656Z","shell.execute_reply":"2025-09-19T13:27:25.55953Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Utilisation de get_dummies pour les variables catégoriques\ndf=pd.get_dummies(df,columns=['smoking_status'])\n","metadata":{"execution":{"iopub.status.busy":"2025-09-19T13:27:25.561764Z","iopub.execute_input":"2025-09-19T13:27:25.562152Z","iopub.status.idle":"2025-09-19T13:27:25.574741Z","shell.execute_reply.started":"2025-09-19T13:27:25.562114Z","shell.execute_reply":"2025-09-19T13:27:25.57385Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"And remove variables that seem irrelevant","metadata":{}},{"cell_type":"code","source":"df=df.drop(['work_type'],axis=1)\ndf=df.drop(['Residence_type'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2025-09-19T13:27:25.57612Z","iopub.execute_input":"2025-09-19T13:27:25.576408Z","iopub.status.idle":"2025-09-19T13:27:25.587695Z","shell.execute_reply.started":"2025-09-19T13:27:25.576381Z","shell.execute_reply":"2025-09-19T13:27:25.586604Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head() #Verification of applied changes","metadata":{"execution":{"iopub.status.busy":"2025-09-19T13:27:25.589325Z","iopub.execute_input":"2025-09-19T13:27:25.58972Z","iopub.status.idle":"2025-09-19T13:27:25.610142Z","shell.execute_reply.started":"2025-09-19T13:27:25.589687Z","shell.execute_reply":"2025-09-19T13:27:25.609018Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# 3 - Machine Learning","metadata":{}},{"cell_type":"markdown","source":"Importint the important libraries","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve, f1_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\n\nfrom imblearn.over_sampling import SMOTE","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T13:27:25.611692Z","iopub.execute_input":"2025-09-19T13:27:25.612154Z","iopub.status.idle":"2025-09-19T13:27:26.720172Z","shell.execute_reply.started":"2025-09-19T13:27:25.612113Z","shell.execute_reply":"2025-09-19T13:27:26.719082Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n**Separating our dataset into train set and test set**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX=df.drop(['stroke'],axis=1)\ny=df['stroke']\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.3, random_state=3)\n","metadata":{"execution":{"iopub.status.busy":"2025-09-19T13:27:26.721556Z","iopub.execute_input":"2025-09-19T13:27:26.721924Z","iopub.status.idle":"2025-09-19T13:27:26.732583Z","shell.execute_reply.started":"2025-09-19T13:27:26.721892Z","shell.execute_reply":"2025-09-19T13:27:26.731526Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Decision trees are usually good candidates for this type of classification problem.","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\ndt_clf=DecisionTreeClassifier(criterion='gini',random_state=3,max_depth=5)\ndt_clf.fit(X_train,y_train)\ny_pred=dt_clf.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2025-09-19T13:27:26.73384Z","iopub.execute_input":"2025-09-19T13:27:26.734125Z","iopub.status.idle":"2025-09-19T13:27:26.760711Z","shell.execute_reply.started":"2025-09-19T13:27:26.734099Z","shell.execute_reply":"2025-09-19T13:27:26.759553Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Let's take a look at the result :","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy : {accuracy:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2025-09-19T13:27:26.762387Z","iopub.execute_input":"2025-09-19T13:27:26.762879Z","iopub.status.idle":"2025-09-19T13:27:26.772494Z","shell.execute_reply.started":"2025-09-19T13:27:26.762834Z","shell.execute_reply":"2025-09-19T13:27:26.770997Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Seems pretty good ! Now the confusion matrix...","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# The matrix\nconfusion_mat = confusion_matrix(y_test, y_pred)\n\n# Plotting\nplt.figure(figsize=(8, 6))\nsns.heatmap(confusion_mat, annot=True, fmt='d', cmap='Blues')\nplt.title('Matrice de Confusion')\nplt.xlabel('Prédiction')\nplt.ylabel('Vraie Valeur')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2025-09-19T13:27:26.773938Z","iopub.execute_input":"2025-09-19T13:27:26.774248Z","iopub.status.idle":"2025-09-19T13:27:27.058944Z","shell.execute_reply.started":"2025-09-19T13:27:26.77422Z","shell.execute_reply":"2025-09-19T13:27:27.057819Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Ok... Is-it really good ?\nLet's look at other metrics","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy : {accuracy:.2f}\")\n\nprecision = precision_score(y_test, y_pred)\nprint(f\"Precision : {precision:.2f}\")\n\nrecall = recall_score(y_test, y_pred)\nprint(f\"Recall : {recall:.2f}\")\n\nf1 = f1_score(y_test, y_pred)\nprint(f\"Score F1 : {f1:.2f}\")\n","metadata":{"execution":{"iopub.status.busy":"2025-09-19T13:27:27.060247Z","iopub.execute_input":"2025-09-19T13:27:27.060584Z","iopub.status.idle":"2025-09-19T13:27:27.079231Z","shell.execute_reply.started":"2025-09-19T13:27:27.060553Z","shell.execute_reply":"2025-09-19T13:27:27.078021Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" We can see that the accuracy is very good, **which might lead us to believe that the model is performing well**, but if we look at the other metrics, we see that our model is in fact, not so good: it classifies almost all the observations in the 'Non-stroke' section.\n\nWhy is this? Probably because we haven't taken into account in our model the large imbalance between our classes: as mentioned before in the dataset, we have many more people labelled 'Non-stroke' than 'Stroke'.","metadata":{}},{"cell_type":"code","source":"stroke_counts = df['stroke'].value_counts()\n\n# Create a bar chart to visualize the distribution\nplt.figure(figsize=(6, 4))\nsns.countplot(data=df, x='stroke')\nplt.title('Stroke Distribution')\nplt.xlabel('Stroke')\nplt.ylabel('Count')\nplt.show()\n\nprint(stroke_counts)","metadata":{"execution":{"iopub.status.busy":"2025-09-19T13:27:27.084567Z","iopub.execute_input":"2025-09-19T13:27:27.08496Z","iopub.status.idle":"2025-09-19T13:27:27.288Z","shell.execute_reply.started":"2025-09-19T13:27:27.084927Z","shell.execute_reply":"2025-09-19T13:27:27.286813Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Let's try using techniques to reduce the unbalancing of our data, in particular by giving different weights to our labels.**","metadata":{}},{"cell_type":"markdown","source":"**Data separation and stratification**","metadata":{}},{"cell_type":"code","source":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.3, stratify = y, random_state=3)","metadata":{"execution":{"iopub.status.busy":"2025-09-19T13:27:27.289435Z","iopub.execute_input":"2025-09-19T13:27:27.28989Z","iopub.status.idle":"2025-09-19T13:27:27.302448Z","shell.execute_reply.started":"2025-09-19T13:27:27.289847Z","shell.execute_reply":"2025-09-19T13:27:27.301235Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Just a little change : \"stratify = y\".\nWith this,we apply a \"statification\" in our data. Stratification involves dividing your data into a training set and a test set in such a way that **the distribution of classes is maintained in both sets**.","metadata":{}},{"cell_type":"markdown","source":"Let's see what it will change :","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\ndt_clf=DecisionTreeClassifier(criterion='gini',random_state=3,max_depth=5)\ndt_clf.fit(X_train,y_train)\ny_pred=dt_clf.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Exactitude : {accuracy:.2f}\")\n\n# Calculer la précision\nprecision = precision_score(y_test, y_pred)\nprint(f\"Précision : {precision:.2f}\")\n\n# Calculer le rappel\nrecall = recall_score(y_test, y_pred)\nprint(f\"Rappel : {recall:.2f}\")\n\n# Calculer le score F1\nf1 = f1_score(y_test, y_pred)\nprint(f\"Score F1 : {f1:.2f}\")\n","metadata":{"execution":{"iopub.status.busy":"2025-09-19T13:27:27.303849Z","iopub.execute_input":"2025-09-19T13:27:27.304351Z","iopub.status.idle":"2025-09-19T13:27:27.331792Z","shell.execute_reply.started":"2025-09-19T13:27:27.304318Z","shell.execute_reply":"2025-09-19T13:27:27.330666Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Humpf... That's disapointing.\nWe will have to try something else.","metadata":{}},{"cell_type":"markdown","source":"**Managing imbalance with class weights**\n\nThis method involves assigning different weights to classes according to their frequency.","metadata":{}},{"cell_type":"code","source":"# Class ponderation : \n\nclass_weights = {0: 1, 1: 25}  # Adjust the weights according to the imbalance in our data\ndt_clf_weighted = DecisionTreeClassifier(criterion='gini', random_state=3, max_depth=5, class_weight=class_weights)\n\ndt_clf_weighted.fit(X_train, y_train)\ny_pred_weighted = dt_clf_weighted.predict(X_test)\n\n# Result\naccuracy_weighted = accuracy_score(y_test, y_pred_weighted)\nrecall_weighted = recall_score(y_test, y_pred_weighted)\nf1_weighted = f1_score(y_test, y_pred_weighted)\nprint(f\"Accuracy with class ponderation : {accuracy_weighted:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2025-09-19T13:27:27.333049Z","iopub.execute_input":"2025-09-19T13:27:27.333358Z","iopub.status.idle":"2025-09-19T13:27:27.357548Z","shell.execute_reply.started":"2025-09-19T13:27:27.33333Z","shell.execute_reply":"2025-09-19T13:27:27.35637Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Our score is far less flattering, but let's see what we have for our other metrics :","metadata":{}},{"cell_type":"code","source":"print(f\"Recall with class ponderation : {recall_weighted:.2f}\")\nprint(f\"F1 with class ponderation : {f1_weighted:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2025-09-19T13:27:27.359048Z","iopub.execute_input":"2025-09-19T13:27:27.359462Z","iopub.status.idle":"2025-09-19T13:27:27.36494Z","shell.execute_reply.started":"2025-09-19T13:27:27.359424Z","shell.execute_reply":"2025-09-19T13:27:27.363907Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"A way more acceptable score for the recall !\n\nAs for the confusion matrix : ","metadata":{}},{"cell_type":"code","source":"confusion_mat2 = confusion_matrix(y_test, y_pred_weighted)\n\n# Créer un heatmap de la matrice de confusion\nplt.figure(figsize=(8, 6))\nsns.heatmap(confusion_mat2, annot=True, fmt='d', cmap='Blues')\nplt.title('Confusion matrix')\nplt.xlabel('Prediction')\nplt.ylabel('Real Value')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2025-09-19T13:27:27.366378Z","iopub.execute_input":"2025-09-19T13:27:27.366829Z","iopub.status.idle":"2025-09-19T13:27:27.577152Z","shell.execute_reply.started":"2025-09-19T13:27:27.366732Z","shell.execute_reply":"2025-09-19T13:27:27.57595Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"At least we now have a more interesting basis for improving our model.","metadata":{}},{"cell_type":"markdown","source":"**Work on hyperparameters**","metadata":{}},{"cell_type":"code","source":"class_weights = {0: 1, 1: 25}  \n# Change on max_depth\ndt_clf_weighted = DecisionTreeClassifier(criterion='gini', random_state=3, max_depth=20, class_weight=class_weights)\n\n# Entraîner le modèle\ndt_clf_weighted.fit(X_train, y_train)\n\n# Faire des prédictions\ny_pred_weighted = dt_clf_weighted.predict(X_test)\n\n# Calculer l'exactitude\naccuracy_weighted = accuracy_score(y_test, y_pred_weighted)\nprint(f\"Exactitude avec pondération des classes : {accuracy_weighted:.2f}\")\nprint(f\"Recall with class ponderation : {recall_weighted:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T13:27:27.578702Z","iopub.execute_input":"2025-09-19T13:27:27.579071Z","iopub.status.idle":"2025-09-19T13:27:27.601456Z","shell.execute_reply.started":"2025-09-19T13:27:27.579042Z","shell.execute_reply":"2025-09-19T13:27:27.600316Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"confusion_mat3 = confusion_matrix(y_test, y_pred_weighted)\n\n# Créer un heatmap de la matrice de confusion\nplt.figure(figsize=(8, 6))\nsns.heatmap(confusion_mat3, annot=True, fmt='d', cmap='Blues')\nplt.title('Confusion matrix with weight ponderation')\nplt.xlabel('Prediction')\nplt.ylabel('Real Value')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T13:27:27.602949Z","iopub.execute_input":"2025-09-19T13:27:27.603883Z","iopub.status.idle":"2025-09-19T13:27:27.816785Z","shell.execute_reply.started":"2025-09-19T13:27:27.603838Z","shell.execute_reply":"2025-09-19T13:27:27.815705Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"With just a change in the depth of our model, we were able to incerease significantly our accuracy while retaining our good recall score.\n\n\nNow, working with GridSearch to determine the best parameters :","metadata":{}},{"cell_type":"code","source":"rf = RandomForestClassifier(class_weight=class_weights, random_state=3)\nparam_grid = {\n    'n_estimators': [100,200],\n    'max_depth': [None,5,10],\n    'min_samples_split': [2,5],\n    'min_samples_leaf': [1,2]\n}\n\ngrid_rf = GridSearchCV(rf, param_grid, scoring='f1', cv=5, n_jobs=-1, verbose=1)\ngrid_rf.fit(X_train, y_train)\n\nbest_rf = grid_rf.best_estimator_\nprint(\"Best params:\", grid_rf.best_params_)\nprint(\"Best F1 (train CV):\", grid_rf.best_score_)\n\n# Évaluation test set\ny_pred_rf = best_rf.predict(X_test)\ny_prob_rf = best_rf.predict_proba(X_test)[:,1]\nprint(classification_report(y_test, y_pred_rf))\nprint(\"ROC-AUC (Test set):\", roc_auc_score(y_test, y_prob_rf))\nsns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True, fmt='d', cmap='Oranges')\nplt.title(\"Confusion Matrix - Best RF\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T13:27:27.818133Z","iopub.execute_input":"2025-09-19T13:27:27.818428Z","iopub.status.idle":"2025-09-19T13:27:53.885157Z","shell.execute_reply.started":"2025-09-19T13:27:27.818401Z","shell.execute_reply":"2025-09-19T13:27:53.883867Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4 - Model comparison","metadata":{}},{"cell_type":"code","source":"# Rebalancement with SMOTE\nsm = SMOTE(random_state=42)\nX_train_res, y_train_res = sm.fit_resample(X_train, y_train)\nprint(\"Counts after SMOTE:\\n\", pd.Series(y_train_res).value_counts())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T13:27:53.887292Z","iopub.execute_input":"2025-09-19T13:27:53.887634Z","iopub.status.idle":"2025-09-19T13:27:53.910784Z","shell.execute_reply.started":"2025-09-19T13:27:53.887599Z","shell.execute_reply":"2025-09-19T13:27:53.90967Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import f1_score, roc_auc_score, precision_recall_curve, auc\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n\nmodels = {\n    \"Logistic Regression\": LogisticRegression(max_iter=1000, class_weight='balanced'),\n    \"Decision Tree\": DecisionTreeClassifier(class_weight='balanced', random_state=3),\n    \"Random Forest\": RandomForestClassifier(class_weight='balanced', random_state=3),\n    \"XGBoost\": XGBClassifier(scale_pos_weight=(len(y_train_res)-sum(y_train_res))/sum(y_train_res), use_label_encoder=False, eval_metric='logloss')\n}\n\nresults = {}\nfor name, model in models.items():\n    model.fit(X_train_res, y_train_res)\n    y_pred = model.predict(X_test)\n    y_prob = model.predict_proba(X_test)[:,1]\n    \n    results[name] = {\n        \"F1\": f1_score(y_test, y_pred),\n        \"ROC-AUC\": roc_auc_score(y_test, y_prob),\n        \"classification_report\": classification_report(y_test, y_pred)\n    }\n\n# Tableau résumé\nsummary = pd.DataFrame(results).T\ndisplay(summary)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T13:27:53.912166Z","iopub.execute_input":"2025-09-19T13:27:53.912526Z","iopub.status.idle":"2025-09-19T13:27:55.829867Z","shell.execute_reply.started":"2025-09-19T13:27:53.912497Z","shell.execute_reply":"2025-09-19T13:27:55.828812Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Use of visualization of th ROC curve","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8,6))\nfor name, model in models.items():\n    y_prob = model.predict_proba(X_test)[:,1]\n    fpr, tpr, _ = roc_curve(y_test, y_prob)\n    plt.plot(fpr, tpr, label=name)\nplt.plot([0,1],[0,1],'k--')\nplt.title(\"ROC Curves\")\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.legend()\nplt.show()\n\nplt.figure(figsize=(8,6))\nfor name, model in models.items():\n    y_prob = model.predict_proba(X_test)[:,1]\n    prec, rec, _ = precision_recall_curve(y_test, y_prob)\n    plt.plot(rec, prec, label=name)\nplt.title(\"Precision-Recall Curves\")\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.legend()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T13:27:55.831237Z","iopub.execute_input":"2025-09-19T13:27:55.831547Z","iopub.status.idle":"2025-09-19T13:27:56.660262Z","shell.execute_reply.started":"2025-09-19T13:27:55.831519Z","shell.execute_reply":"2025-09-19T13:27:56.659159Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The ROC curves and Precision-Recall curves allow us to visually compare the performance of different models in distinguishing between stroke and non-stroke cases.\n\nROC Curves: The ROC curve plots the True Positive Rate against the False Positive Rate at different thresholds. A model with a curve closer to the top-left corner demonstrates better discrimination. We can see that the Random Forest and XGBoost models outperform the baseline Decision Tree in terms of ROC-AUC.\n\nPrecision-Recall Curves: Given the class imbalance in the dataset, Precision-Recall curves are particularly informative. They show the trade-off between precision (positive predictive value) and recall (sensitivity) for each threshold. Models trained with class weighting and SMOTE demonstrate improved recall without sacrificing too much precision, indicating they are better at correctly identifying stroke cases.\n\nOverall, these curves confirm that handling class imbalance and tuning hyperparameters significantly improves model performance, especially for the minority class.","metadata":{}}]}